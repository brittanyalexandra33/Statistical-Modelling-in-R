{
  "hash": "b5b230c7c8a4e7922008de2b705a94cf",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Poisson Modelling\"\nauthor: \"Brittany Alexandra\"\ndate: \"2025-06-01\"\n\nformat:\n  html:\n    theme: cerulean\n    toc: true\n    toc-depth: 2          \n    toc-location: left    \n    code-fold: true\n    code-tools: true\n\neditor_options: \n  markdown: \n    wrap: 72\n---\n\n\n# Modelling processes that evolve randomly over time\n\nWelcome to the soft introduction into Poisson modelling in R!\n\nMany things in life can be modelled with the poisson process as it quite\nliterally models the long-term average rate of which random events occur\nindepdently. Its subjectively the most widely used model of a point\nprocess in time, and is suitable for modelling *frequencies* and\nprobabilities*,* for example:\n\n-   The frequency of goals scored by a team in a soccer match\n\n-   The probability two teams will score no goals in a soccer match\n\n-   The freqeuncy inbound calls to a call center\n\n-   The probability you receive 10 calls in one hour to a call center\n\n-   The frequency of unique visitors to a website\n\n-   The probability you receive 5 unique visitors to a website in 30\n    minutes\n\n-   The frequency walk-in arrivals to a physical location (customers or\n    patients)\n\n-   The probability you receive 30 walk-in arrivals to a physical\n    location in 2 hours.\n\n-   The frequency of volcanic eruptions\n\n-   The probability there will be 2 volcanic eruptions in the next 10\n    years.\n\nAll of these scenarios have the following in common which allow us to\ndescribe the response:\n\n-   The expected value is discrete\n\n-   The expected value is right skewed\n\n-   The expected value is bounded, where our values can only be ≥ 0\n\n-   The variance is non-constant, and increases equivalent to our\n    expected value\n\nSo now that we have an understanding of what types of scenarios follow a\npoisson distribution, what do we do with this information? Well...\n\nIn linear regression, our expected value is a linear combination of our\nexplanatory variables such as $\\mu_i = \\beta_0 + \\beta_1 x_i$, but when\nmodelling with a poisson distribution, we must tweak this in R to ensure\nour expected value, $\\mu_i$ can never be negative. After all, we\ncouldn't have a negative number for any of the previous examples\nlisted... Imagine having a negative number of unique visitors to a\nwebsite! That would upset your boss lol.\n\nTo accommodate this, we use a link function to map our parameter of\ninterest, $\\mu_i$ to the real number line. We do this, so that no matter\nhow negative the linear predictor is $(\\beta_0 $ or $\\beta_1$), our\nexpected value $(\\mu_i)$ will always be positive.\n\nTo ensure $\\mu_i > 0$, R (and the underlying GLM framework) uses a **log\nlink**\n$\\log(mu_i) = \\beta_0 + \\beta_1 x_i ⇒ \\mu_i =exp(beta_0 + \\beta_1 x_i)$.\nThis transformation guarantees that $\\mu_i$ is always positive, even if\nthe linear predictor is negative. You can think of the model as being\nlinear **on the log scale**. Further, due to the logarithmic\ntransformation, we must interpret coefficients multiplicatively: a\none-unit increase in $x$ is associated with a **multiplicative** change\nin $\\mu_i$.\n\nThe two plots below help visualize how the Poisson model transforms\nvalues using a **log link**. The log ensures the model stays linear on\nthe log scale, while the exponential ensures predictions for the mean\nresponse, μ, are always positive.\n\n-   The log link function transforms the expected value of our response\n    variable, $\\mu$ (which must be ≥ 0) into a value on the real number\n    line. This is shown in the left plot: as $\\mu$increases, η=log⁡(μ)\n    grows slowly but without bounds.\n\n-   Conversely, the inverse link function (right plot) transforms any\n    real-valued model prediction, n, back to a valid expected count\n    μ=exp⁡(η), which is always positive. This ensures our Poisson model\n    makes realistic predictions for count data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required libraries\nlibrary(ggplot2)\n\n\n# Create data for mu (positive values only)\nmu <- seq(0.01, 10, length.out = 500)\neta_from_mu <- log(mu)\ndf1 <- data.frame(mu = mu, eta = eta_from_mu)\n\n# Create data for eta (real number line)\neta <- seq(-5, 5, length.out = 500)\nmu_from_eta <- exp(eta)\ndf2 <- data.frame(eta = eta, mu = mu_from_eta)\n\n# Plot 1: Link function (log)\n ggplot(df1, aes(x = mu, y = eta)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(\n    title = \"Log Link Function: η = log(μ)\",\n    x = expression(mu ~ \"(mean of response)\"),\n    y = expression(eta ~ \"(linear predictor)\")\n  ) +\n  theme_minimal(base_size = 14)\n```\n\n::: {.cell-output-display}\n![](poisson_introduction_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot 2: Inverse link function (exp)\nggplot(df2, aes(x = eta, y = mu)) +\n  geom_line(color = \"forestgreen\", linewidth = 1) +\n  labs(\n    title = \"Inverse Link Function: μ = exp(η)\",\n    x = expression(eta ~ \"(linear predictor)\"),\n    y = expression(mu ~ \"(mean of response)\")\n  ) +\n  theme_minimal(base_size = 14)\n```\n\n::: {.cell-output-display}\n![](poisson_introduction_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n:::\n",
    "supporting": [
      "poisson_introduction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}