[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I appreciate you dropping byüòÄ\nMy name's Bri. I enjoy statistical modelling and making predictions.\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.1     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.5.2     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "poisson_earthquakes.html",
    "href": "poisson_earthquakes.html",
    "title": "Poisson Modelling",
    "section": "",
    "text": "Introduction\n\nWhen is the next volcano due to erupt? Any moment now, unfortunately! (Give or take 1000 years or so).\nA volcano could happen this afternoon, or it might not happen for another 1000 years. Volcanoes are almost impossible to predict; they seem to happen completely at random.\nHowever, we do know of a statistical distribution that counts the number of events in a fixed space of time‚Ä¶the Poisson distribution! The Poisson process counts the number of events occurring in a fixed time or space, when events occur independently and at a constant average rate, where the formula for our statistical model is as follows:\n\\(Y_i \\sim \\text{Poisson}(\\mu_i),\\) where \\(\\mu_i = \\beta_0 + \\beta_1 x_i\\quad\\)\nDiving a bit into understanding the foundations of how we will use this statistical model in R‚Ä¶ It is worth noting that we need to use a link function to map our parameter of interest, \\(\\mu_i\\) , to the real number line, where \\(log(\\mu_i) = \\beta_0 + \\beta_1 x_i\\).\nIn other words, the expected value of our response variable, \\(\\mu_i\\), must be non negative \\((\\mu_i\\ ‚â• 0)\\). However, because we are using a log-link function, the model actually estimates \\(\\log(\\mu_i)\\) which can take on any real number, that is \\(- \\infty &lt; \\log(\\mu_i) &lt; +\\infty\\)\nToday, we will look at how to use the poisson distribution to model the occurrence of volcanic events per year in Country A. This country is composed of smaller areas that regularly record information on the following:\n\narea.type: Categorical variable with 9 categories.\ntotal.land.area: Total land area in square kms\ntotal.area: Total area (including water) in square kms\nshape.length: Length of the shape of the area in kms\nUrbanRural: Recoded variable area.type into bigger categories\nprevious.eruption: Number of previous volcanic eruptions in the are\nY: Number of eruptions during the observation period. The observation time is ONE\nyear for all areas.\nearthquakes.year: Average number of earthquakes per year in the area\n\nA quick note, this blog is not focused on the exploratory part of this data, and will not go in-depth to all the metrics and terms used, but I aim to add another page soon explaining the terminology!\n\n\nStep 1. Choosing variables to include in the model\n\nEach analysis begins with selecting which variables to include in our model. Contrary to intuition, we do not want to include every variable available ‚Äî for several key reasons:\n\nOccam‚Äôs Razor suggests that, all else equal, simpler models are preferable to more complex ones.\nIncluding too many variables can introduce multicollinearity, where highly correlated predictors make coefficient estimates unstable and unreliable.\n\nThe methods to identify appropriate explanatory variables are listed below (this is specific to our analysis):\n\nDomain knowledge: Always the most important source of insight. Correlation plots: Useful for detecting multicollinearity between explanatory variables.\nChi-square tests: To test for associations between categorical variables.\nAkaike Information Criterion (AIC): Balances model fit with model complexity to guide selection relative to comparative models.\n\nWe aim to choose explanatory variables that are strongly associated with the response variable while avoiding those that are highly correlated with each other. We will walk through choosing appropriate variables to model our response, Y, with an example, focusing on the variables area.type and UrbanRural\nIn the pairs plot below, we can see area.type and UrbanRuralare moderately colinear with a correlation of 0.42 and therefore only one should in the model.\n\n\nCode\npairs20x(data)\n\n\n\n\n\n\n1.1 Domain Knowledge\nIt‚Äôs important to ask whether there is a contextual benefit to including area.type or UrbanRural. As we are interested in modelling the frequency of eruptions, and not the impact of specific area types, I am unbiased as to which variable we include in the model from a contextual standpoint.\n\n\n1.2 Chi-square Tests\nAs established by our pairs plot, it looks like we face a few colinear variables, and we are interested in looking into UrbanRural and area.type.\nWe can test the hypothesis that they both variables contain similar information using a chi-square test. This test checks for a statistically significant association between two categorical variables, with the null hypothesis being that there is there is no association between two categorical variables.\n\\[\nH_0: \\text{The two categorical variables are independent.}\n\\]\nBelow, we can see the test result has a small p-value of 0.0005, thus showing no evidence to reject the null hypothesis ‚Äî suggesting that the distribution of UrbanRural and area.type categories is likely due to chance, and they are not significantly different.\nGiven area.type and UrbanRural are not statistically different, and they have eight anad three levels, respectively, we will opt for the simpler explanatory variable with three levels, UrbanRural.\nWhy do we want to reduce our model complexity? Well, simpler models are easier to interpret when we are quantifying their impact on the response. Remember, this is statistical modelling NOT machine learning. We need to be able to explain every part going on, and the effect each variable has on the result.\nFrom a computational standpoint, it enables a faster convergence of models, allows parameter coefficients to be more stable, and helps avoids overfitting.\n\n\nCode\n # We can see that we have a small p-value of 0.00049 (p-val &lt; 0.05), therefore have no evidence to reject the null hypothesis that the observed distribution difference across the categories 'UrbanRural` and `area.type` is due to chance \ntabledata &lt;- table(data$UrbanRural, data$area.type)\nchiResult &lt;- chisq.test(tabledata, simulate.p.value = TRUE, B = 2000)\n\n# Clean summary\ncat(\"Chi-squared test (with simulated p-value, B = 2000):\\n\")\n\n\nChi-squared test (with simulated p-value, B = 2000):\n\n\nCode\ncat(\"X-squared =\", round(chiResult$statistic, 3), \"\\n\")\n\n\nX-squared = 37478 \n\n\nCode\ncat(\"Degrees of freedom =\", chiResult$parameter, \"\\n\")\n\n\nDegrees of freedom = NA \n\n\nCode\ncat(\"P-value =\", format.pval(chiResult$p.value, digits = 4, eps = 1e-4), \"\\n\")\n\n\nP-value = 0.0004998 \n\n\n\n\n1.3 AIC\nAIC is a likelihood based metric often used to compare two statistical models. A lower AIC is favourable to a higher AIC, as it indicates a better blend of model complexity while still explaining the data well.\nIt‚Äôs important to note that there is no single ‚Äúcorrect‚Äù way to choose variables. For instance, UrbanRural has a slightly higher AIC (253157) than area.type (253043), but the difference is marginal and in my personal opinion, not worth incorporating into the model due to its additional levels. (UrbanRural has 3 levels while area.type has 5).\n\n\nCode\nmodel1 &lt;- glm(Y ~ UrbanRural, family = \"poisson\", data = data)\nmodel2 &lt;- glm(Y ~ area.type, family = \"poisson\", data = data)\n\n# Create comparison data frame\ncomparison &lt;- data.frame(\n  Model = c(\"UrbanRural\", \"Area Type\"),\n  AIC = c(AIC(model1), AIC(model2)))\n\n# Pretty table\ncomparison %&gt;%\n  kable(\"html\", caption = \"&lt;strong&gt; Model Comparison: AIC &lt;/strong&gt;\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), \n                full_width = FALSE, \n                position = \"center\")\n\n\n\n\nModel Comparison: AIC\n\n\nModel\nAIC\n\n\n\n\nUrbanRural\n253157.0\n\n\nArea Type\n253042.8\n\n\n\n\n\n\n\n\nLastly, our plots indicate both variables follow similar distribution patterns. The effect of Sea, which only has three observations, is negligible and including it would risk biasing our model due to its higher proportion of earthquakes, but smaller sample size.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Ensure categorical variables are factors\ndata &lt;- data %&gt;%\n  mutate(\n    UrbanRural = factor(UrbanRural),\n    area.type = factor(area.type)\n  )\n\n# --- Add counts directly to data frame ---\ndata_urban &lt;- data %&gt;%\n  group_by(UrbanRural) %&gt;%\n  mutate(n = n()) %&gt;%\n  ungroup()\n\ndata_area &lt;- data %&gt;%\n  group_by(area.type) %&gt;%\n  mutate(n = n()) %&gt;%\n  ungroup()\n\n# --- Plot for UrbanRural ---\np1 &lt;- ggplot(data_urban, aes(x = UrbanRural, y = Y)) +\n  geom_boxplot(fill = \"lightpink\") +\n  stat_summary(\n    fun = max, geom = \"text\",\n    aes(label = paste0(\"n = \", n)),\n    vjust = -0.5, size = 3\n  ) +\n  labs(\n    title = \"Earthquakes per Urban/Rural Area\",\n    x = \"UrbanRural\",\n    y = \"Earthquakes per Year\"\n  ) +\n  theme_minimal()\n\n# --- Plot for area.type ---\np2 &lt;- ggplot(data_area, aes(x = area.type, y = Y)) +\n  geom_boxplot(fill = \"lightblue\") +\n  stat_summary(\n    fun = max, geom = \"text\",\n    aes(label = paste0(\"n = \", n)),\n    vjust = -0.5, size = 3\n  ) +\n  labs(\n    title = \"Earthquakes per Area Type\",\n    x = \"Area Type\",\n    y = \"Earthquakes per Year\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# --- Combine plots side by side ---\np1\n\n\n\n\n\nCode\np2\n\n\n\n\n\n\n\n\nStep 2: Fitting the model\n\nGiven that the response variable, Y, represents a count of discrete positive numbers, we have chosen to apply a generalized linear model that utilities a Poisson distribution to predict Y, the frequency of eruptions.\nTo convert the expected average count of eruptions, denoted as ¬µi, from the Poisson distribution into a linear predictor, we have used the log link function. This is because we must ensure all expected values are greater than 0 (our model should not output an expected negative amount of earthquakes!), account for non constant variance, and assume a discrete responses (we can‚Äôt have 2.5 earthquakes either! what would half an earthquake mean?)\nWe have used explanatory variables; previous.eruption, UrbanRural, earthquakes.year, and total.area. All explanatory variables had significant contributions towards explaining model variance (pval : &lt;2e-16).\nWe will initially fit a model with all the variables and see which is the optimal outcome based on which model has the lowest AIC, thereby penalizing model complexity and rewarding goodness of fit. In addition, We iteratively removed insignificant variables each model to final converge on glm_model4, which had the (subjectively) best combination of low AIC and low model complexity.\nHowever, not all assumptions were not satisfied, as we can see an increase in variance with an increase in the Y (number of eruptions) as the mean increases. If our model was perfect, our predicted values would follow closely to the purple line.\n\n\nCode\n############################################################\n# Split data into test and training\n############################################################\ntrain_index &lt;- createDataPartition(data$Y, p = 0.8, list = FALSE)\ntrain_data &lt;- data[train_index, ]\ntest_data &lt;- data[-train_index, ]\n\n\n#Fit model with all predictor variables and see what the model tries best with stepwise regression \nglm_model1 &lt;- glm(Y ~ previous.eruption + UrbanRural + shape.length + total.area + total.land.area + earthquakes.year, family = \"poisson\", data = train_data)\n#summary(glm_model1)\n\nglm_model2 &lt;- glm(Y ~ previous.eruption + earthquakes.year + UrbanRural + total.area + shape.length, data = train_data, family = poisson)\n# summary(glm_model2)\n\nglm_model3 &lt;- glm(Y ~ UrbanRural + previous.eruption + earthquakes.year, data = train_data, family = poisson)\n# summary(glm_model3)\n\n# Best model \nglm_model4 &lt;- glm(Y ~ previous.eruption + earthquakes.year + UrbanRural + total.area, family = poisson, data = train_data)\n#summary(glm_model4)\n\n\n# MODEL COMPARISON \n#glm_model3 has the best median between low AIC and low model complexity \nAIC(glm_model1, glm_model2, glm_model3, glm_model4)\n\n\n           df      AIC\nglm_model1  8 147011.3\nglm_model2  7 147015.8\nglm_model3  5 147619.6\nglm_model4  6 147034.7\n\n\nCode\npredictions_glm4 &lt;- predict(glm_model4, newdata = test_data, type = \"response\")\ntest_data$predictions_glm4 &lt;- predictions_glm4\n\n# kind of bad model \nggplot(test_data, aes(x = Y, y = predictions_glm4, col = UrbanRural)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  geom_line(aes(x = Y, y = Y), color = \"purple\", alpha = 0.5) + # Ideal fit line\n  labs(x = \"Actual\", y = \"Predicted\", title = \"Actual vs. Predicted values from chosen Poisson model \") + \n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\n##############################\n# Fit model with full data now \n##############################\nglm_model3_full &lt;- glm(Y ~ UrbanRural + previous.eruption + earthquakes.year + total.area,\n                 family = \"poisson\", data = data)\n\n# summary(glm_model3_full)\n\n\n\n\nStep 3: Diagnostic checks on our chosen model\n\nBelow, we run diagnostic checks on our chosen model\n\nThe Chi-squared ANOVA checks if all levels are significant within our model. For example, the UrbanRural variable has 3 levels (degrees of freedom +1) , and we can see from the significant P-value of &lt;2.2e-16 that they are all significant.\n\n\nCode\n# All levels are significant for our best model\nanova(glm_model4, test = \"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: Y\n\nTerms added sequentially (first to last)\n\n                  Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nNULL                              14993     161666              \nprevious.eruption  1    56281     14992     105386 &lt; 2.2e-16 ***\nearthquakes.year   1      178     14991     105208 &lt; 2.2e-16 ***\nUrbanRural         2    10817     14989      94391 &lt; 2.2e-16 ***\ntotal.area         1      587     14988      93804 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCooks distance measures the influence of a specific data point on the overall model. For example, it quantifies how much the models predictions would change if these datapoints were removed. Below, we can see there are a few datapoints that clearly stick out, but all have a distance under 0.5 so we are not concerned about their influence.\n\n\nCode\n# A simple function to generate a cooks distance plot \ncooks20x(glm_model3)\n\n\n\n\n\nWe use a normality check to see how the residuals of our model are distributed. Residuals are the differences between the observed values and the values predicted by out model, simply put as\n\n\\[\nr_i = y_i - \\hat{y}_i$.\n\\]\n\n\nCode\nnormcheck(glm_model3)\n\n\n\n\n\n\n\nStep 4: Quantifying the impact of our variables on the frequency of earthquakes\n\nWe have evidence to reject the null hypothesis that the model is a good fit (pval : 0) .\nAll variables were significant in explaining the variance in our response (p-val &lt; 0.05).\nHowever, we can visually see that this model still offers some useful information from the above plot.\nHolding all other variables constant:\n\nWe estimate that, for every 1 square km increase in total area, the expected number of eruptions for a given time period increases by 1.86%\nWe estimate that, for every 1 unit increase in previous eruptions, the expected number of eruptions for a given time period decrease by 76.61%\nWe estimate that, for every 1 unit increase in earthquakes.year (average number of earthquakes per year in the area), the expected number of eruptions for a given time period increase by 4.13%.\nWe estimate that the expected number of earthquakes in a given time period for the ‚ÄúSettlement‚Äù Urban Rural category is 26.3% higher than the expected number of earthquakes in the ‚ÄúOther‚Äù category.\nWe estimate that the expected number of earthquakes in a given time period for the ‚ÄúUrban‚Äù Urban Rural category is 44.84% lower than the expected number of earthquakes in the ‚ÄúOther‚Äù category.\n\n\n\nCode\nsummary(glm_model3_full) \n\n\n\nCall:\nglm(formula = Y ~ UrbanRural + previous.eruption + earthquakes.year + \n    total.area, family = \"poisson\", data = data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-6.9865  -2.3027  -0.7174   1.2060  10.2700  \n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 3.1674850  0.0079876  396.55   &lt;2e-16 ***\nUrbanRuralRural settlement  0.2337399  0.0131489   17.78   &lt;2e-16 ***\nUrbanRuralUrban            -0.5950103  0.0078943  -75.37   &lt;2e-16 ***\nprevious.eruption          -1.4528968  0.0070815 -205.17   &lt;2e-16 ***\nearthquakes.year            0.0404475  0.0027978   14.46   &lt;2e-16 ***\ntotal.area                  0.0184193  0.0006451   28.55   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 200101  on 18738  degrees of freedom\nResidual deviance: 116577  on 18733  degrees of freedom\nAIC: 183123\n\nNumber of Fisher Scoring iterations: 5\n\n\nCode\n100*(exp(coef(glm_model3_full))-1)  \n\n\n               (Intercept) UrbanRuralRural settlement \n               2274.768259                  26.331584 \n           UrbanRuralUrban          previous.eruption \n                -44.844311                 -76.610823 \n          earthquakes.year                 total.area \n                  4.127662                   1.858996 \n\n\n\n\nStep 5: Adding more complexity to our model to improve its explanatory power\n\nGreat! Now that we have established our baseline model, it‚Äôs time to see how we can improve it one way to do this is by adding interaction effects. Interaction effects take into account the effect of one explanatory variable on the response variable, depending on the level of another explanatory variable. For example, our UrbanRural variable has 3 levels, and the effect of each level on the response may differ based on the other explanatory variables.\nBelow, we explore one interaction effect, and notice a distinction between previous.eruption and earthquakes.year. The interaction was fit and kept due it‚Äôs significant p-value (pval : &lt; 2.2e-16).\n\n\nCode\n##############################\n# Lets investigate the relationships\n##############################\nfit1 &lt;- glm(Y ~ previous.eruption*earthquakes.year, data = data, family = poisson)\ninteract_plot(fit1, pred = previous.eruption, modx = earthquakes.year)\n\n\n\n\n\nAfter comparing our previous simple poisson model, with our current poisson model with an interaction effect, we can see the interaction model actually provides a lower AIC!\n\n\nCode\n##############################\n# Fit model with full data now \n##############################\nglm_model5 &lt;- glm(Y ~ previous.eruption*earthquakes.year + UrbanRural + total.area, family = poisson, data = data)\nsummary(glm_model5) # All significant \n\n\n\nCall:\nglm(formula = Y ~ previous.eruption * earthquakes.year + UrbanRural + \n    total.area, family = poisson, data = data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-6.9849  -2.0430  -0.5682   1.2069   9.8643  \n\nCoefficients:\n                                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                         3.121215   0.008044  388.01   &lt;2e-16 ***\nprevious.eruption                  -1.002563   0.009295 -107.87   &lt;2e-16 ***\nearthquakes.year                    0.093767   0.002908   32.24   &lt;2e-16 ***\nUrbanRuralRural settlement          0.233251   0.013147   17.74   &lt;2e-16 ***\nUrbanRuralUrban                    -0.597354   0.007891  -75.70   &lt;2e-16 ***\ntotal.area                          0.018134   0.000645   28.12   &lt;2e-16 ***\nprevious.eruption:earthquakes.year -0.599499   0.010139  -59.12   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 200101  on 18738  degrees of freedom\nResidual deviance: 112713  on 18732  degrees of freedom\nAIC: 179261\n\nNumber of Fisher Scoring iterations: 5\n\n\nCode\nAIC(glm_model4, glm_model5)\n\n\nWarning in AIC.default(glm_model4, glm_model5): models are not all fitted to\nthe same number of observations\n\n\n           df      AIC\nglm_model4  6 147034.7\nglm_model5  7 179261.2\n\n\nWe can also see the predictions from this model perform slightly better than our previous model.\n\n\nCode\n##############################\n# SHOW PREDICTIONS\n##############################\npredictions_glm5 &lt;- predict(glm_model5, newdata = test_data, type = \"response\")\ntest_data$predictions_glm5 &lt;- predictions_glm5\n\n# kind of bad model \nggplot(test_data, aes(x = Y, y = predictions_glm5, col = UrbanRural)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  geom_line(aes(x = Y, y = Y), color = \"red\", alpha = 0.5) + # Ideal fit line\n  labs(x = \"Actual\", y = \"Predicted\", title = \"Actual vs. Predicted Poisson model \") + \n  theme_minimal()\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nSimilar to step Step 2, we must run diagnostic checks on our model. After all, we can‚Äôt blindly code something and believe it to be accurate!\nWe can see our interaction is significant with a p-value of &lt;2.2e-17\n\n\nCode\nanova(glm_model5, test = \"Chisq\")\n\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: Y\n\nTerms added sequentially (first to last)\n\n                                   Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)\nNULL                                               18738     200101          \nprevious.eruption                   1    69679     18737     130423 &lt; 2.2e-16\nearthquakes.year                    1      184     18736     130238 &lt; 2.2e-16\nUrbanRural                          2    12950     18734     117288 &lt; 2.2e-16\ntotal.area                          1      711     18733     116577 &lt; 2.2e-16\nprevious.eruption:earthquakes.year  1     3864     18732     112713 &lt; 2.2e-16\n                                      \nNULL                                  \nprevious.eruption                  ***\nearthquakes.year                   ***\nUrbanRural                         ***\ntotal.area                         ***\nprevious.eruption:earthquakes.year ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\n# ##############################\n# # Diagnostic checks\n# ##############################\n# cooks20x(glm_model5)\n# plot(glm_model5, lty = 2, pch = substr(data$UrbanRural, 1, 1))\n\n\n\n\nStep 6: Concluding statements and interpretations from our final model\n\nAs the response variable, number of eruptions during the observation period, is a count, we have fit a generalized linear model with a Poisson response distribution.\nWe have 5 significant explanatory terms (pval all &lt;0.05); earthquakes.year, total.area, previous.eruption, total.area, and UrbanRural. The interaction plot above suggests a difference between the expected number of eruptions depending on how many eruptions there were in the previous year (per area) and the average number of eruptions (per area).\nHence, a poisson model with an interaction term between previous.eruption and earthquakes.year was fit. The interaction term was significant (pval : &lt; 2e-16) so it remained in the model.\nAll assumptions were satisfied. However, we still cannot trust the results from the Poisson model (pval: 0 )\nHolding all other variables constant‚Ä¶\n\nWe estimate that, for every 1 unit increase in the number of previous volcanic eruptions (previous.eruptions), the expected number eruptions in a given time period decreases by 63.3%.\n\nThis is further decreased by 45.1% for every increase in the average number of earthquakes per year in the area (earthquakes.year)\n\nWe estimate that, for every 1 unit increase in the number of average earthquakes per year, the expected number of eruptions in a given time period increases by 9.83%.\n\nThere is further decreased by 45.1% for every increase the number of previous volcanic eruptions (previous.eruption).\n\nWe estimate that, for every 1 square km increase in total area, the expected number of eruptions in a given time period increases by 1.83%\nWe estimate that the expected number of eruptions in a given time period is 44.97% lower in ‚ÄúUrban‚Äù (UrbanRural) areas compared to ‚ÄúOther‚Äù areas\nWe estimate that the expected number of eruptions in a given period is 26.27% higher in ‚ÄúSettlement‚Äù (UrbanRural) areas compared to ‚ÄúOther areas‚Äù\n\n\n\nCode\nsummary(glm_model5)\n\n\n\nCall:\nglm(formula = Y ~ previous.eruption * earthquakes.year + UrbanRural + \n    total.area, family = poisson, data = data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-6.9849  -2.0430  -0.5682   1.2069   9.8643  \n\nCoefficients:\n                                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                         3.121215   0.008044  388.01   &lt;2e-16 ***\nprevious.eruption                  -1.002563   0.009295 -107.87   &lt;2e-16 ***\nearthquakes.year                    0.093767   0.002908   32.24   &lt;2e-16 ***\nUrbanRuralRural settlement          0.233251   0.013147   17.74   &lt;2e-16 ***\nUrbanRuralUrban                    -0.597354   0.007891  -75.70   &lt;2e-16 ***\ntotal.area                          0.018134   0.000645   28.12   &lt;2e-16 ***\nprevious.eruption:earthquakes.year -0.599499   0.010139  -59.12   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 200101  on 18738  degrees of freedom\nResidual deviance: 112713  on 18732  degrees of freedom\nAIC: 179261\n\nNumber of Fisher Scoring iterations: 5\n\n\nCode\n# pval_glm_model5 &lt;- 1 - pchisq(90402, 14987)\n# print(paste(\"We cannot still trust the most optimal model found as it has a small p-value of\", pval_glm_model5, \"indicating the poisson model does not provide a good fit \"))\n\n#Interpreting coefficients\n100*(exp(coef(glm_model5))-1)  \n\n\n                       (Intercept)                  previous.eruption \n                       2167.392233                         -63.306220 \n                  earthquakes.year         UrbanRuralRural settlement \n                          9.830385                          26.269789 \n                   UrbanRuralUrban                         total.area \n                        -44.973416                           1.829907 \nprevious.eruption:earthquakes.year \n                        -45.091323 \n\n\n\n\nExtra : Mathematical interpretation of our model\n\nOur final model is:\n\\[\nlog(\\mu_i)=\\beta_0+\\beta_1p_i+\\beta_2e_i+\\beta_3s_i+\\beta_4u_i+\\beta_5t_i+\\beta_6p_ie_i\n\\]\nWhere :\n\n\\(\\mu_i\\) is the number of eruptions during the observation period and Y (the expected number of eruptions in the ‚ÄúOther‚Äù Urban Area) has a poisson distribution with mean \\(\\mu_i\\)\n\\(\\text{p}_{i}\\) represents the number of previous eruptions in the area\n\\(\\text{e}_{i}\\) represents the average number of earthquakes per year in the area\nThe factor variable \\(\\text{UrbanRural}\\) has 3 dummy variables where \\(\\text{s}_{i}\\) takes the value 1 if the observation is from Settlement and 0 otherwise. In addition \\(\\text{u}_{i}\\) takes the value 1 if the observation is from Urban, and 0 otherwise.\n\\(\\text{t}_{i}\\) represents the total area (including water) in square km.\n\nHere, ‚ÄúOther‚Äù (within the UrbanRural factor) is our baseline level."
  },
  {
    "objectID": "binomial_image.html",
    "href": "binomial_image.html",
    "title": "Binomial Image Recognition",
    "section": "",
    "text": "Introduction\nThe US post office want to electronically scan hand-written numbers and be able to predict what was written for the ZIP code. A ZIP code tells them where a mail item needs to be delivered. We will look at the numbers 3 and 7 only ‚Äî to see if we can distinguish these two numbers ‚Äî to illustrate ideas about prediction based on logistic regression.\nIn this dataset, each hand-written digit is represented as a 16 x 16 array of pixels.\nEach pixel is given a grey-scale value in the range [‚àí1, 1] with -1 representing white and 1 representing black. There are thus 16 x 16 = 256 numbers representing a particular digit, which we can take as the values of 256 variables, v1, . . . , v256, say\n\n\nStep 1: Reading in data\n\n\nCode\n# Note: -1 is white and 1 is black \n\ntrain.df &lt;- read.table(\"data/binomial_image/train.txt\")\ntest.df &lt;- read.table(\"data/binomial_image/test.txt\")\n\n# Append D to the dataframe\nnames(train.df) = c(\"D\", paste(\"V\", 1:256, sep=\"\"))\nnames(test.df) = c(\"D\", paste(\"V\", 1:256, sep = \"\"))\n\n\n\n\nStep 2: View the first 25 samples of handwritten 3s and 7s to identify which are the best at discriminating\nHere, we can see cells that would be best at differentiating between a 3 and 7 are the cells that have most structural difference of white and black space i.e.¬†protruding instances of black colour that are in areas unique to that number.\nThis can be seen in the following areas of each image:\n\nBottom Cells: It has a very pronounced black curve in the bottom right corner, which forms a loop. This is very contrasting to a 7, which remains open and essentially finishes being black at the bottom right.\nMiddle: The middle of this three is black and extends far from the right to the left of the cell, (almost like a straight line) providing more pronounced differentiation compared to a 7, which does not have this feature in this data set and instead has white area.\nTop-left: The top of this cell is curved and filled in black, while a 7 in this data set typically has a distinct diagonal black line in the top-left corner.\n\n\n\nCode\n# Set up the plotting area to have a 5x5 grid and minimal margins\npar(mfrow=c(5,5), mar = c(1,1,1,1))\n# Loop through the first 25 rows of the data frame\nfor(k in 1:25){\n  \n  # Convert the k-th row (excluding the first column) into a 16x16 matrix\n  z = matrix(unlist(train.df[k,-1]), 16,16)\n  \n  # Initialize zz as a copy of z\n  zz = z\n  \n    # Mirror the matrix horizontally\n  for(j in 16:1)zz[,j]=z[,17-j]\n  \n  # Plot the mirrored matrix as an image with grayscale colors\n  image(zz, col = gray((32:0)/32))\n  \n  # Add a box around the plot\n  box()\n\n  # Add the value of D in the top-left corner of the plot\n  text(0.1,0.9,train.df$D[k], cex=1.5)\n}\n\n\n\n\n\n\n\nStep 3: Computing the correlation\nHere, we will compute the correlation between D and V1, V2,‚Ä¶ V256, and identify which of these variables have the highest absolute correlations (i.e either very large and negative or very large and positive).\n\n\nCode\n# Correlation with D, without D\ncrs=cor(train.df)[,\"D\"][-1]\n\n# Sort absolute values in in decending order\nsort(abs(crs), decreasing=T)[1:20]\n\n\n     V185      V170      V105      V220      V235      V201      V229      V120 \n0.8714422 0.8331768 0.8208550 0.8144829 0.8053422 0.7994677 0.7824515 0.7795704 \n     V219      V230      V104      V189      V205      V169      V234      V121 \n0.7767427 0.7646643 0.7578159 0.7554507 0.7546277 0.7504911 0.7430652 0.7393237 \n     V204      V186      V173      V221 \n0.7375292 0.7332635 0.7254096 0.6929391"
  },
  {
    "objectID": "poisson_introduction.html",
    "href": "poisson_introduction.html",
    "title": "poisson_introduction",
    "section": "",
    "text": "test test\n\n\nCode\n# Load required libraries\nlibrary(ggplot2)\nlibrary(patchwork)  # For side-by-side plots\n\n# Create data for mu (positive values only)\nmu &lt;- seq(0.01, 10, length.out = 500)\neta_from_mu &lt;- log(mu)\ndf1 &lt;- data.frame(mu = mu, eta = eta_from_mu)\n\n# Create data for eta (real number line)\neta &lt;- seq(-5, 5, length.out = 500)\nmu_from_eta &lt;- exp(eta)\ndf2 &lt;- data.frame(eta = eta, mu = mu_from_eta)\n\n# Plot 1: Link function (log)\np1 &lt;- ggplot(df1, aes(x = mu, y = eta)) +\n  geom_line(color = \"blue\", size = 1) +\n  labs(\n    title = \"Log Link Function: Œ∑ = log(Œº)\",\n    x = expression(mu ~ \"(mean of response)\"),\n    y = expression(eta ~ \"(linear predictor)\")\n  ) +\n  theme_minimal(base_size = 14)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\nCode\n# Plot 2: Inverse link function (exp)\np2 &lt;- ggplot(df2, aes(x = eta, y = mu)) +\n  geom_line(color = \"forestgreen\", size = 1) +\n  labs(\n    title = \"Inverse Link Function: Œº = exp(Œ∑)\",\n    x = expression(eta ~ \"(linear predictor)\"),\n    y = expression(mu ~ \"(mean of response)\")\n  ) +\n  theme_minimal(base_size = 14)\n\n# Combine the plots side by side\np1 \n\n\n\n\n\nCode\np2"
  },
  {
    "objectID": "binomial_introduction.html",
    "href": "binomial_introduction.html",
    "title": "binomial_introduction",
    "section": "",
    "text": "test"
  }
]